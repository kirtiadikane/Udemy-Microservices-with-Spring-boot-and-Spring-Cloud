Step  - Spring Cloud API Gateway
-------------------------------------------------------------------------
Initial

- http://localhost:8765/CURRENCY-EXCHANGE/currency-exchange/from/USD/to/INR

- http://localhost:8765/CURRENCY-CONVERSION/currency-conversion/from/USD/to/INR/quantity/10

- http://localhost:8765/CURRENCY-CONVERSION/currency-conversion-feign/from/USD/to/INR/quantity/10



Lower Case

- http://localhost:8765/currency-exchange/currency-exchange/from/USD/to/INR

- http://localhost:8765/currency-conversion/currency-conversion/from/USD/to/INR/quantity/10

- http://localhost:8765/currency-conversion/currency-conversion-feign/from/USD/to/INR/quantity/10


************************************************************
Step 24: Exploring Routes with Spring Cloud Gateway
------------------------------------------------------------
http://localhost:8765/get


Custom Routes

- http://localhost:8765/currency-exchange/from/USD/to/INR

- http://localhost:8765/currency-conversion/from/USD/to/INR/quantity/10

- http://localhost:8765/currency-conversion-feign/from/USD/to/INR/quantity/10

- http://localhost:8765/currency-conversion-feign-new/from/USD/to/INR/quantity/10


------------------------------------------------------------------------------------------------------
Step 25 - Implementing Spring Cloud Gateway Logging Filter
Spring Cloud gateway is an awesome way to route to your APIs and implement your crosscutting concerns. Things like security, monitoring, metrics, 
these are the best things that you can implement in a Spring Cloud gateway. This is built on top of Spring WebFlux, and that's the reason why we needed to use the reactive approach.
Some of the important features of Spring Cloud Gateway are it can match request on any request attribute.


------------------------------------------------------------------------------------------------------
Step 26 - Getting started with Circuit Breaker - Resilience4j

we have talked about the fact that in a microservices architecture there is a complex call chain. As shown in the example here, a microservice can call another microservice.
That microservice might be dependent on another microservice and so on and so forth. And what would happen if one of these services is down or is very slow? Let's say microservice 
four is down or it's very, very slow. What would happen? There would be an impact on the entire chain. If the microservice four is down, then microservice three also will be down,
microservice two also will be down, because these are all depending on microservice 4. Even if it's slow, then there is a corresponding impact on the other microservices too. In 
these microservices, there will be a buildup of calls because this microservice is slow. All these chains also get impacted.
So the questions are, can we return a fallback response if a service is down?
If I see that the microservice four is down, in the microservice three, can I return a fallback response? Can I configure a default response? This might not always be possible.
For example, in the case of a credit card transaction, or something of that kind, you do not have any fallback responses possible. But in the case of a shopping application, instead 
of returning a set of products you might return a default set of products. That's possible. The other question to consider is can we implement a circuit breaker pattern to reduce 
the load? If I see that microservice four is down, instead of repeatedly hitting it and causing it to go down, can I actually return the default response back without even hitting
the microservice? 

The other question to consider is, can we retry requests in case of temporary failures? If there is a temporary failure from a microservice four, can I retry it a few times
and only when it has failed multiple times, I return a default response back.
The last question is, can we implement something like rate limiting?
I want to allow only certain number of calls to a specific microservice in a specific period of time.
If you're using Spring Boot, then there is a circuit breaker framework which is available, which is called Resilience4j.
Resilience4j is a lightweight, easy to use, fault tolerant library inspired by Netflix Hystrix. In the previous versions of Spring Boot and Spring Cloud, Netflix Hystrix was the 
recommended circuit breaker framework. However, with the evolution of Java eight and functional programming, Resilience4j has become the recommended framework.

You can integrate Resilience4j with Spring Boot, the first thing that we need to do is to add the dependencies on Resilience4j Spring Boot 2, Spring Boot starter actuator and Spring Boot starter AOP.


------------------------------------------------------------------------------------------------------
Step 28 - Playing with Circuit Breaker Features of Resilience4j

A circuit breaker can be in three different states, closed, open, and half open.
What are the different states?
Closed is when I am calling the dependent microservice continuously. So in a closed state I'll always be calling the dependent microservice.
In a open state, the circuit breaker will not call the dependent microservice. It'll directly return the fallback response.
And in a half open state, a circuit secure breaker would be sending a percentage of requests to the dependent microservice,
and for rest of the requests, it would return the hard coded response or the fallback response back.

When does the circuit secure breaker switch from one state to another?
For example, the circuit breaker is in the closed state. When you start the application up the circuit breaker is typically in a closed state. Let's say I'm calling the dependent microservice
10,000 times and I see that all of them are failing or I see that 90% of them are failing. In that kind of scenario, the circuit breaker would switch to a open state. Once it switches through 
an open state it waits for a little while. It, there's a wait duration that you can configure. After that wait duration the circuit breaker would switch to a half open state. During the half 
open state. The circuit breaker would try and see if the dependent microservice is up. So it sends a percentage of the request. You can configure how much percentage. It would send let's say 
10% or 20% of the request to the dependent microservice. And if it gets proper responses for that then it would go back to the closed state. If it does not get proper responses, then it would 
go back to the open state.

documentation- https://resilience4j.readme.io/docs/circuitbreaker



------------------------------------------------------------------------------------------------------
Section 7: Docker with Microservices using Spring Boot and Spring Cloud - V2
------------------------------------------------------------------------------------------------------
Step 00 - Match made in Heaven - Docker and Microservices

We have talked about the fact that enterprises are heading towards microservices architectures. You're building a number of small microservices that communicate with each 
other, and help you to achieve your required functionality. As part of our microservices architectures, we build a number of small focused microservices. One of the biggest 
advantages of microservices, is the flexibility to innovate and build applications in different programming languages. You can build microservices using Java and Spring Boot, 
as we are doing in this specific course. You can also build microservices using Go, Python, JavaScript, and a variety of other programming languages. But as we start exploring 
the microservices architecture, and start implementing different languages, the deployments of these microservices become complex. Let's say the movie microservice and the 
customer microservice are implemented in Java, and let's say the other ones are implemented in Python. You do not want different deployment procedures for each of these 
microservice types. How can you get a common way to deploy multiple microservices irrespective of the language, or the framework that is used to build these microservices? 
How can we get one way of deploying Go, Java, Python, or JavaScript microservices? That's where containers come into picture, and the most popular container tool is Docker. 
What you can do is to create Docker images for each of these microservices. So for all the microservices that we looked over here, you can create Docker images. 
The Docker image contains everything that a microservice needs to run. The Application Runtime, JDK, Python, or NodeJS. The application code for Java applications. It might 
just be the JAR, your dependencies that you need to run the application. So, everything is part of your Docker image, and once you have this Docker image, you can run these 
as docker containers the same way on any infrastructure. So you can run these Docker images on your local machine in a corporate data center, and also in the Cloud, whether 
it's AWS, Azure, or Google Cloud. All of these support running docker containers in a wide variety of ways.


------------------------------------------------------------------------------------------------------
Step 02 - Your First Docker Usecase - Deploy a Spring Boot Application

In this step, let's discuss a use case where Docker is most useful. You are working on a team, you are the star developer in the team. You're working on a challenging project 
with very tight deadlines. You'd want a application deployed to an end environment quickly. You have a very good friend of yours working in the operations team, and you go to 
him and tell, "Okay let's quickly deploy the application to the QA environment." And you tell him, "Okay, launch up terminal." He launches a terminal, on Windows you might be 
using Command Prompt, so launch up either Terminal or Command Prompt and type this along with me. He says, "Okay, let's check if Docker is installed."
docker--version.
Type it in. Okay, Docker is installed.
Now, let's run the application. Let's deploy the application. 

Run this -> docker run in28min/todo-rest-api-h2:1.0.0.RELEASE

It says, "Okay, this is the command, go ahead and run it." You press Enter and you see that lot of magic unfolds, your friend from the operations team ask, "What's happening?"
You tell him, "Okay, wait, hold on, let's see what would happen." And you'd see that right now it's downloading something, it's pulling something, it's "Downloaded a new image," 
it says. And you are seeing now that a Spring Boot application is being launched up. And you'd see that in about 20 seconds, we are able to launch up a Spring Boot application. 
Your operations team friend is stunned. He tells you, "Hey, on this machine, Java is not installed. How's it running?" Your friend in the operations team is actually working in 
a few older projects. He's used to the manual approach. He usually gets a document that says, "Okay, you need this hardware and you'd want to install Linux XYZ version, and on 
top of it, install Java 8.5.10, install Tomcat a.a.b and then download this JAR and then run it using this command." And what he tries to do typically, is try to follow these 
instructions and install the application. And typically he makes a lot of mistakes. When I'm looking at a document, and trying to type it down a multiple set of instructions, 
there's a high chance that I make a mistake while deploying something. He's asking you now, "How are we able to deploy this application that you have built so easily?" You tell 
your friend, "Okay, that's the magic of Docker."



------------------------------------------------------------------------------------------------------
Step 03 - Docker Concepts - Registry, Repository, Tag, Image and Containers

https://hub.docker.com/r/in28min/todo-rest-api-h2/tags
Default Registry->    https://hub.docker.com/
Repository-> in28min/todo-rest-api-h2
Tags->  1.0.0.RELEASE

Image - A static template - A set of bytes
Container - Running version of image

Image is like a Class. Container is like an object
-p = port
-p 5000:5000 => -p {HostPort}:{ContainerPort}

docker run -p 5000:5000 in28min/todo-rest-api-h2:1.0.0.RELEASE        => runs the docker image


In the previous step, we were able to quickly launch up an application just running a simple instruction. And your friend from the operations team is very, very curious. He's asking, 
Where is this application downloaded from? You have typed in something in here 
in28min/todo-rest-api-h2
What does this mean? What is this and where this coming in from? So let's answer some of the important questions in this specific step. Over here when we run this command what is 
happening is an image is downloaded. From where? From something called hub.docker.com. Hub.docker.com is something called a docker registry. A registry contains a lot of repositories, 
a lot of different versions of different applications. And because this is a public registry anybody can access this. Typically when you're working in an enterprise we would be 
using private repositories so that our images can only be accessed by somebody who has the right credentials. If this is the registry where our application is, how do we locate 
our application, right? 

So over here you can type in https://hub.docker.com/r/in28min/todo-rest-api-h2/ If you type this in and press enter you would go to something called a repository. 
So hub.docker.com is a registry. It can contain multiple repositories and inside that in28min/todo-rest-api-h2/ is a repository storing all diversions of a specific application. 
So this is something that hosts a number of tags and we specified 1.0.0 release as the version that we would want to use. Now you might be wondering what does this image contain?  
You'd see that this image is about 102 mb. This image actually contains all the things that your application needs to run. It contains the right software. For example, Java, 
a specific version of Java Java eight or Java 11, whichever version you'd want to use. It contains all the libraries your API needs. Your todo-rest-API might need 15 libraries. 
It contains all of them and it contains any other dependency that your application might need to be able to run. When we ran this command, this image was downloaded to our machine, 
so a local image was created. So from the registry, the image is downloaded to our, your machine and once the image is downloaded, it is ran as an application in your machine. 
And this is what is called a container image is something static. So on the repository image is a set of bytes, that's it. When it's downloaded even then the image is just a set 
of bytes. And when it's running it's called a container. So image is a static version and container is a running version. And for the same image you can have multiple containers 
running.  I see that the Springboot application is running but I would want to be able to access it. How can I do that? If you go further down you'd see that it's running on 
port 5,000. Let's go and try to run it localhost:5000/hello-world-bean.
Why is there error?
Just press control C This would terminate the running container and let's do a clear and go up and try and run this command again. However, this time with option So we need to 
put an option called 
docker run -p 5000:5000 in28min/todo-rest-api-h2:1.0.0.RELEASE

any container that you run is part of something called a bridge network in Docker. You can kind of think of it like an internal docker network. Nobody will be able to access it 
unless you specifically expose it onto the host onto the system where your container is running. So what we are doing in here is we are saying I want to take the internal port, 
the container port 5,000 and map it to a host port to report on the system where the container is running which is 5,000. So now I would be able to access the application on 
Port 5,000. You'd see that the application is launched up. 
Yep, it took about 20 seconds.
when we execute the command, the image is downloaded from something called docker hub. Docker hub is something called a docker registry. A registry contains a number of repositories 
when we are specifying the name in here, it's actually name of one of the repositories and we are specifying which version, which tag of that repository to get. And once we specify 
that, we saw that the image was downloaded and running. The running version of the image is called a container. A image is a static version and the running dynamic version of it is 
called a container. And at the end we also saw that we had to publish the container port to a host port to be able to access the application.
docker run -p 5000:5000 in28min/todo-rest-api-h2:1.0.0.RELEASE


docker logs container_id   = shows all the logs of the application

docker logs -f container_id   = starts following the logs of the application

docker container ls  = lists all the running container
CONTAINER ID    IMAGE       COMMAND      CREATED        STATUS    POSTS    NAMES

We can run multiple containers from the same image
-d = detach
1st container localhost:5000/hello-world 
docker run -p 5000:5000 -d in28min/todo-rest-api-h2:1.0.0.RELEASE

2nd container localhost:5001/hello-world
docker run -p 5001:5000 -d in28min/todo-rest-api-h2:1.0.0.RELEASE

docker container ls -a  = lists the all the containers irrespective of the STATUS (Up or Exited)

docker container stop container_id   = stops the container

docker images   = shows the docker images that are local to us. The images which have been pulled from the docker registry.
REPOSITORY    TAG     IMAGE ID   CREATED    SIZE

docker container stop container_id = stops the container


------------------------------------------------------------------------------------------------------
Step 05 - Understanding Docker Architecture - Docker Client, Docker Engine
The Architecture of Docker.

The place we were running the commands in is called a Docker client and when we type something in the Docker client, the command is sent out to something called a 
Docker Daemon or a Docker engine for execution. So even the local installation of Docker uses a client server kind of architecture. So when you install Docker desktop 
we were installing both the Docker client and the Docker Daemon. The Docker Daemon is responsible for managing the containers. It's responsible for managing the local 
images and it is responsible for pulling something from the image registry if you need it or pushing a locally created image to a image registry.
The first two parts of that is very easy, right? Docker Daemon is responsible for managing our local containers and local images.
All the local containers are managed by the Docker Daemon or the Docker engine, which is running on our local machine.
The Docker Daemon also manages the images which were downloaded. The Docker Daemon knows that there is a local image for the specific repository and the specific tag.
We are running the command in Docker client. The Docker client sends the docker command to the Docker Daemon and the Docker Daemon now sees that if image is not available 
locally. then It says in this repository with this tag, the image is not available locally. So what it's doing, it's going to the repository and fetching that image down 
for us. So it'll fetch down the image and then run it as a container.
So the Docker Daemon is responsible for managing our local containers, local images and also pulling images from the image repository/registry if something is not available 
on our local. It's responsible for creating images and also pushing out images to the image registry so that somebody else can make use of them.
One of the additional capabilities that Docker Daemon has is it can process instructions to create images as well.


------------------------------------------------------------------------------------------------------
Step 06 - Why is Docker Popular

One of the most important things, is you should understand the big picture around why Docker is becoming famous. One of the things we saw, was installing Docker on our local 
machine was very, very easy, so developers can use Docker easily. Now, what's happening these days, is most of our environments are deployed on the cloud. The awesome thing 
about Docker is you can install Docker on cloud also very, very easily. Most of the cloud providers actually provide container based services. So they provide services where 
you just need to tell, "Run this container," and it would automatically run on the cloud.

Before Docker, virtual machines were very, very popular. You have the hardware, you have a host operating system installed on top of the hardware, and we had something called 
the Hypervisor to manage your virtual machines. So each of these was a virtual machine, so you have virtual machine one, virtual machine two, virtual machine three. And each 
virtual machine had a guest OS, and on top of it, you have the software that you'd want to install to run your application, and on top of it is your application. One of the 
major problems with these virtual machine architecture, was typically these are heavy weight. We had two operating systems, host operating system and guest operating system, 
and that makes the whole thing a little heavy. And that's where Docker comes in. If you have some infrastructure and if you have some host operating system installed on top of it, 
all that you need to do is to install the Docker engine for that specific operating system and Docker would take care of managing these containers. The Docker image contains all 
that is needed to run a container. All the libraries, all the software, are directly part of these containers. Because there is just one OS, the host OS, Docker is relatively 
lightweight, and therefore it is very, very efficient. And that's why you would see that all the cloud providers provide a number of services around Docker.
Today, It's very, very easy to deploy something related to Docker onto any of the cloud providers.
Azure provides a service called Azure Container Service. AWS, Amazon Web Services, provides a service called Elastic Container Service. So the thing which we are understanding 
right now, is the fact that using Docker on local is very easy and using Docker on the cloud is also very easy. And that's the reason why Docker is becoming really, really popular 
during the last few years.


------------------------------------------------------------------------------------------------------
Step 07 - Playing with Docker Images

docker images   = shows the docker images that are local to us. The images which have been pulled from the docker registry.
REPOSITORY                     TAG               IMAGE ID         CREATED         SIZE
in28min/todo-rest-api-h2       1.0.0.RELEASE     f8049a029560     2 months ago     143MB


docker tag repository_name:existing_tag repository_name:new_tag    = Create new tag from the existing tag
Ex: docker tag in28min/todo-rest-api-h2:1.0.0.RELEASE in28min/todo-rest-api-h2:latest


docker pull image_name   = pulls/downloads the image from the registry to the local
Ex: docker pull mysql


docker run image_name   = docker run checks if the image available in the local, If it's not available in the local, then it pulls it and creates a container.


docker search mysql   = search for any image which contains mysql.
NAME    DESCRIPTION    STARS    OFFICIAL      AUTOMATED
 
docker official images are a curated set of docker repositories. Basically, docker has a team which looks at these images make sure that
they're meeting certain standards, and they publish all these content in the official images.


docker image history image_id/repository name:tag    =  get all the history, all the steps that were involved in creating that specific image.

docker image inspect image_id    =    It gives information related to the tags, containers which were created from it, some configuration related to that.

docker image remove image_id  =  removes the image from the local



------------------------------------------------------------------------------------------------------
Step 08 - Playing with Docker Containers

creating a container from the specific image and launch up the container in detach mode
docker container run -p 5000:5000 -d in28min/todo-rest-api-h2:1.0.0.RELEASE


docker container pause container_id    = pauses/stops the container (we can't access the API of this container when it is paused)


docker container unpause container_id    = Unpause all processes within one or more containers


docker container inspect container_id   = Gives details about that specific container like the container when it is created, current status, 
image details, platform, default bindings, volumes, etc


docker container prune   = This removes all the stopped containers

stop => SIGTERM  => gracefull shutdown
docker container stop container_id   =   It's shut down the executor service, closes the entity manager factory, drops the table sequences and shuts down the connection pool. 
The container was given some time to finish its processes to shutdown gracefully. In technical terms, when I do a container stop, the signal which is sent to the container is something 
called sigterm. It means take about 10 seconds and make sure that you gracefully complete your execution.


docker container kill container_id   = The container stopped as it is. It won't really given time to do anything. 
In technical terms, what happens is a signal called sigkill is sent out to the container and it immediately stops.

The command which you should use most of the times. Actually, 99.99% of the times is docker container stop. You'd want to give your container time to shutdown gracefully.


Restart policy: 
Two of the most popular values for restart policy are always and no. The default restart policy is no.

docker container run -p 5000:5000 -d --restart=always in28min/todo-rest-api-h2:1.0.0.RELEASE

Whenever we restart the Docker Desktop and the Docker Daemon restarts, it sees if there are any container with the restart policy of always.
If there are any, it would launch them up.
The restart policy is very useful, especially if you have things like databases which you would want to keep them always running. You can set a restart policy of always. And even if the Docker daemon restarts by accident at the start of the Docker daemon, 
that specific container would be always launched up.


------------------------------------------------------------------------------------------------------
Step 09 - Playing with Docker Commands - stats, system

docker events   =  Used to monitor the events which are happening with the Docker engine or the Docker daemon.

docker top container_id = Used to check what is the top process, which is running in a specific container.
PID   USER   TIME    COMMAND

docker stats =  Shows all the statistics regarding the containers which are running.
How much amount of cpu is it making use of? How much memory is it making use of? memory percentage.


We can set memory and CPU limits for the containers.
docker run -p 5000:5000 -m 512m --cpu-quota 5000 -d in28min/todo-rest-api-h2:1.0.0.RELEASE
-m  = memory , here 512m is 512MB 
--cpu-quota = CPU quota , here 5000 is 5 % of CPU


docker system df    = It helps us to look at what are the different resources that the Docker daemon manages and how much size each one of them have.
Docker daemon manages your images, your containers.


------------------------------------------------------------------------------------------------------
Step 10 - Introduction to Distributed Tracing
Step 11 - Launching Zipkin Container using Docker


docker run -p 9411:9411 openzipkin/zipkin:2.23   = Launch Zipkin as a docker container

http://localhost:9411/zipkin

------------------------------------------------------------------------------------------------------
 Step 12 00 - Getting Started with Observability and OpenTelemetry
 
Monitoring is all about looking at metrics, logs, traces.  Monitoring is reactive. You're looking at what has happened.
Observability, on the other hand, is proactive.
Observability focuses on, how well do we understand what's happening in a system? This step one in observability is gathering data: metrics, logs, or traces.
But the most important step in observability is to get the intelligence. There are a lot of resources out there these days. You have AI, ML, and a lot of things that you 
can make use of to get intelligence to detect if something wrong is happening in your system. So observability is one step about monitoring. 
Gathering data is what monitoring focuses on. So monitoring is actually a subset of observability. In monitoring, we try and get metrics, logs, and traces.
And in observability, we focus on getting intelligence from this data, and hopefully this intelligence would help us to detect problems faster.



What is OpenTelemetry?
All applications have metrics, logs, and traces. If you go a few years back, there are different standards, different tools, different APIs, different SDKs for 
each of metrics, logs, and traces.
The question is, why do we need to have a separate standard for each one of these? One standard for metrics, one standard for logs, one standard for traces. 
There were a lot of initiatives around consolidating metrics, logs, and traces into a single standard.
And one of the most important results from those initiatives is OpenTelemetry. It's a collection of tools, APIs, and SDKs to instrument, generate, collect, and export telemetry data, 
so things like metrics, logs, traces. Instead of having different standards for different things, why not have just one standard for all the things related to gathering data and gathering your 
telemetry data? That's where OpenTelemetry comes into picture. Today, almost every cloud platform out there, AWS Azure, Google Cloud, provides support for telemetry in one form or the other.
 
 
------------------------------------------------------------------------------------------------------

Step 12 : Distributed Tracing - Zipkin  
https://github.com/in28minutes/spring-microservices-v3/blob/main/v3-upgrade.md

Let's consider a simple scenario.
A request is flowing through multiple microservices and it is taking a lot of time. You want to find out how much time the request is spending in each microservice and 
you want to find out which microservice is consuming the most amount of time. That's where something called distributed tracing is useful. It helps you to trace a request 
across microservices. You'd be able to find out details about the request and you'll also be able to find out how much time the request is spending in each of these 
microservices, and one of the most popular tools to implement distributed tracing is something called Zipkin.
The way distributed tracing would work is that each of the microservices would send the tracing information out to the distributed server and the distributed tracing server 
would have all that information stored in a database and would provide a UI, and you can query against the UI and find information about the requests which are executed.


Now, why are there changes between Spring Boot 2 and Spring Boot 3?
Thing is, in Spring Boot 2, for tracing configuration,
basically, you'd want to be able to configure what kind of requests you'd want to trace, how many requests you want to trace. Do you want to trace every request? All that is 
called tracing configuration, and in Spring Boot 2, the recommended approach to do that was to use something called Spring Cloud Sleuth. This would send the information to the 
tracer library, which is Brave, and from Brave, we would send the information out to Zipkin.
However, in Spring Boot 3, the recommendation is to use Micrometer. Sleuth can only handle traces. However, Micrometer can handle logs, metrics, and traces as well. 
Micrometer is a vendor-neutral application observability facade. It can instrument your JVM-based application code without vendor lock-in. The great thing about Micrometer 
is that it can handle observations, basically metrics and logs, and traces as well, and instead of Brave, what we'd be using in Spring Boot 3 is OpenTelemetry. OpenTelemetry is, 
again, an open standard for metrics, logs, and tracing. So, what we are doing is we are moving from trace-specific configuration, which was used in Spring Boot 2, to open standards. 
We want to have the same things, like Micrometer, OpenTelemetry, which are common for tracing, logging, and metrics as well.

That's why, in Spring Boot 3, we are switching over to Micrometer and OpenTelemetry.

Spring Boot 2:      Sleuth (Tracing Configuration) 
                  > Brave (Tracer library) 
                  > Zipkin
            
Spring Boot3 :  Micrometer 
              > OpenTelemetry 
              > Zipkin 

Micrometer - Vendor-neutral application observability facade.  
Instrument your JVM-based application code without vendor lock-in.  
    Observation (Metrics & Logs) + Tracing.
    
Open Telemetry  - Simplified Observability (metrics, logs, and traces)    
       
            
Sampling: 
If you trace all the requests which are coming into all the microservices, there will be a big performance impact and that's why you can configure how much percentage of the 
request you'd want to sample. Configure it in application.properties file.



------------------------------------------------------------------------------------------------------
 Step 13:
 feign micrometer - Integrate Micrometer for Feign Requests
 
 
------------------------------------------------------------------------------------------------------
 Spring Boot 3.0+ - https://github.com/in28minutes/spring-microservices-v3/tree/main/04.docker
Create the docker image of any microservice:

First add the docker image configuration in pom.xml and then run the below command.
spring-boot:build-image -DskipTests   =  To create a image of the project 
use this command in Run as configuration  


To create the Docker image, the spring-boot-maven-plugin makes use of a lot of Docker images. And for these Docker images,
we would want to configure a pullPolicy of IF_NOT_PRESENT. The default pullPolicy is ALWAYS.
Whenever you build a container image, Spring Boot would fetch the base images and build the image for your specific project. And all these base images which are needed,
spring-boot-maven-plugin, by default, would get them from the Docker Registry.
However, what I'm configuring in here is to make it a little bit more efficient. What I'm saying is only if the images are not present locally, go and pull them.
Otherwise, use the images, which are present locally. So IF_NOT_PRESENT.


------------------------------------------------------------------------------------------------------
 Step 16 - Getting Started with Docker Compose - Currency Exchange Microservice
 
 In Last Step, we launched up the currency exchange service, and we would want to launch up a lot more containers. So we want to create containers for all the microservices 
 that we have in here. And also we want to launch up Zipkin and RabbitMQ. Launching up each one of these with commands, like we executed until now, is not going to be a easy 
 thing and that's the reason why we go for something called Docker Compose.

Docker Compose is a tool for defining and running multi container Docker applications. You can simply configure a YAML file, and with a single command you can launch up all 
these services which are defined inside the YAML file.


------------------------------------------------------------------------------------------------------
 What is a Kubernetes cluster? 
 A Kubernetes cluster is a set of nodes that run containerized applications. Containerizing applications packages an app with its dependences and some necessary services. 
 They are more lightweight and flexible than virtual machines.
 
 Master node- manages cluster
 Worker node- run your applications
 What is the difference between worker and master node in Kubernetes?
The worker nodes are responsible for running the containers and doing any work assigned to them by the master node. 
The master node looks after: scheduling and scaling applications. maintaining the state of the cluster.


kubectl - kube controller

If you go to hub.docker.com/u/in28min


When we executed the command kubectl create deployment, Kubernetes created a deployment, a replica set, and a pod.
When we executed the command kubectl exposed deployment, Kubernetes created a service for us.

Commands executed in this section:

https://github.com/in28minutes/spring-microservices-v2/tree/main/05.kubernetes#commands



docker run -p 8080:8080 in28min/hello-world-rest-api:0.0.1.RELEASE
 
Deploy application to kubernetes cluster and gives the deployment id
kubectl create deployment hello-world-rest-api --image=in28min/hello-world-rest-api:0.0.1.RELEASE

Expose a service/application to the outside world
kubectl expose deployment hello-world-rest-api --type=LoadBalancer --port=8080

kubectl scale deployment hello-world-rest-api --replicas=3
kubectl delete pod hello-world-rest-api-58ff5dd898-62l9d
kubectl autoscale deployment hello-world-rest-api --max=10 --cpu-percent=70
kubectl edit deployment hello-world-rest-api #minReadySeconds: 15
kubectl set image deployment hello-world-rest-api hello-world-rest-api=in28min/hello-world-rest-api:0.0.2.RELEASE
 
gcloud container clusters get-credentials in28minutes-cluster --zone us-central1-a --project solid-course-258105
kubectl create deployment hello-world-rest-api --image=in28min/hello-world-rest-api:0.0.1.RELEASE
kubectl expose deployment hello-world-rest-api --type=LoadBalancer --port=8080
kubectl set image deployment hello-world-rest-api hello-world-rest-api=DUMMY_IMAGE:TEST
kubectl get events --sort-by=.metadata.creationTimestamp
kubectl set image deployment hello-world-rest-api hello-world-rest-api=in28min/hello-world-rest-api:0.0.2.RELEASE
kubectl get events --sort-by=.metadata.creationTimestamp
kubectl get componentstatuses
kubectl get pods --all-namespaces
 
kubectl get events
kubectl get pods
kubectl get replicaset
kubectl get deployment
kubectl get service
 

kubectl get replicasets
kubectl get replicaset
 
kubectl scale deployment hello-world-rest-api --replicas=3
kubectl get pods
kubectl get replicaset
kubectl get events
kubectl get events --sort.by=.metadata.creationTimestamp
 
kubectl get rs
kubectl get rs -o wide
kubectl set image deployment hello-world-rest-api hello-world-rest-api=DUMMY_IMAGE:TEST
kubectl get rs -o wide
kubectl get pods
kubectl describe pod hello-world-rest-api-85995ddd5c-msjsm
kubectl get events --sort-by=.metadata.creationTimestamp
 
kubectl set image deployment hello-world-rest-api hello-world-rest-api=in28min/hello-world-rest-api:0.0.2.RELEASE
kubectl get events --sort-by=.metadata.creationTimestamp
kubectl get pods -o wide
kubectl delete pod hello-world-rest-api-67c79fd44f-n6c7l
kubectl get pods -o wide
kubectl delete pod hello-world-rest-api-67c79fd44f-8bhdt
 
gcloud container clusters get-credentials in28minutes-cluster --zone us-central1-c --project solid-course-258105
docker login
docker push in28min/mmv2-currency-exchange-service:0.0.11-SNAPSHOT
docker push in28min/mmv2-currency-conversion-service:0.0.11-SNAPSHOT


215. Step 16 - Deploy Microservices to Kubernetes & Understand Service Discovery
kubectl create deployment currency-exchange --image=in28min/mmv2-currency-exchange-service:0.0.11-SNAPSHOT
kubectl expose deployment currency-exchange --type=LoadBalancer --port=8000
kubectl get svc
kubectl get services
kubectl get pods
kubectl get po
kubectl get replicaset
kubectl get rs
kubectl get all
 
kubectl create deployment currency-conversion --image=in28min/mmv2-currency-conversion-service:0.0.11-SNAPSHOT
kubectl expose deployment currency-conversion --type=LoadBalancer --port=8100
 
kubectl get svc --watch


216. Step 17 - Creating Declarative Configuration Kubernetes YAML for Microservices

kubectl get deployments
kubectl get deployment currency-exchange -o yaml
kubectl get deployment currency-exchange -o yaml >> deployment.yaml 
kubectl get service currency-exchange -o yaml >> service.yaml 
 
219. Step 20 - Deploying Microservices using Kubernetes YAML Configuration

kubectl diff -f deployment.yaml
kubectl apply -f deployment.yaml
 
kubectl delete all -l app=currency-exchange
kubectl delete all -l app=currency-conversion

221. Step 22 - Creating Environment Variables to enable Microservice Communication

docker push in28min/mmv2-currency-conversion-service:0.0.12-SNAPSHOT
docker push in28min/mmv2-currency-exchange-service:0.0.12-SNAPSHOT


222. Step 23 - Understanding Centralized Configuration in Kubernetes - Config Maps

kubectl create configmap currency-conversion --from-literal=CURRENCY_EXCHANGE_URI=http://currency-exchange
kubectl get configmap
kubectl get configmap currency-conversion
kubectl get configmap currency-conversion -o yaml >> configmap.yaml


kubectl rollout history deployment currency-conversion
kubectl rollout history deployment currency-exchange
kubectl rollout undo deployment currency-exchange --to-revision=1
 
kubectl logs currency-exchange-9fc6f979b-2gmn8
kubectl logs -f currency-exchange-9fc6f979b-2gmn8 
 
Step 27 - Autoscaling Microservices with Kubernetes

kubectl autoscale deployment currency-exchange --min=1 --max=3 --cpu-percent=5 
kubectl get hpa
 
kubectl top pod
kubectl top nodes
kubectl get hpa
kubectl delete hpa currency-exchange
 
kubectl create configmap currency-conversion --from-literal=CURRENCY_EXCHANGE_URI=http://currency-exchange
kubectl get configmap
 
kubectl get configmap currency-conversion -o yaml >> configmap.yaml
 
watch -n 0.1 curl http://34.66.241.150:8100/currency-conversion-feign/from/USD/to/INR/quantity/10
 
docker push in28min/mmv2-currency-conversion-service:0.0.12-SNAPSHOT
docker push in28min/mmv2-currency-exchange-service:0.0.12-SNAPSHOT


------------------------------------------------------------------------------------------------------
Step 07 - Understanding Pods in Kubernetes
 
Pods is the most important concept in Kubernetes. A pod is the smallest deployable unit in Kubernetes. You might think containers are the smallest 
deployable unit, but no, in Kubernetes the smallest deployment unit is actually the pod. Let's consider a question. I want to create a container in 
Kubernetes. Can you do it without a pod? The answer is no. You cannot have a container in Kubernetes without a pod. Your container lives inside a pod.

Each pod has a unique IP address. A pod can actually contain multiple containers. All the containers which are present in a pod share resources within 
the same pod, the containers can talk to each other using local host. A pod in Kubernetes is a collection of containers.
So a pod can contain multiple containers that can run on a host, that can run on a single node.



Namespace is a very important concept, it provides isolations for parts of the cluster from other parts of the cluster.
What do I mean? Let's say you have your development and QA environments running inside the same cluster. How do you separate the resources of DEV from 
the resources of QA? One of the options is to create separate namespaces for QA and DEV, and associate each of the resources with that specific namespace.


The important thing that you need to remember about pod is a pod provides a way to put your containers together,
it gives them an IP address, and also it provides a categorization for all these containers by associating them with labels.
On any Kubernetes nodes there can be multiple pods, and each of these pods can contain multiple containers that are running as part of them.

kubectl get pods
kubectl get pods -o wide
kubectl explain pods
kubectl describe pod hello-world-rest-api-58ff5dd898-9trh2
 
------------------------------------------------------------------------------------------------------
Step 08 - Understanding ReplicaSets in Kubernetes

kubectl get replicasets
kubectl get replicaset
kubectl get rs
kubectl get pods -o wide
kubectl delete pods hello-world-rest-api-58ff5dd898-9trh2
kubectl get pods -o wide

kubectl scale deployment hello-world-rest-api --replicas=3
kubectl get events
kubectl get events --sort-by=.metadata.creationTimestamp
kubectl explain replicaset


Replica sets ensure that a specific number of pods are running at all times. The replica set always keeps monitoring the pods
and if there are lesser number of pods than what is needed then it creates the pods. We said we would want one pod running all time and when it goes down to zero, 
immediately the replica set looks at it and says, okay, there is one pod missing I'll need to start it up and it kicks off a new pod.
So in kubernetes, whenever somebody talks about replica set to you, it's all about maintaining the number of pods. So a pod is where your containers run. A pod provides 
a grouping for the containers and a replica set ensures that a set of pods, a specified number of pods are always running.


------------------------------------------------------------------------------------------------------
Step 09 - Understanding Deployment in Kubernetes

Why do we need a deployment? Now, let's say I have a specific version of application deployed.
Let's call it V1. And let's say we would want to update to a new version, let's say V2. Typically, what do we want when we are updating applications?
We would want zero downtime.

kubectl get rs
NAME     DESIRED     CURRENT    READY    AGE

kubectl get rs -o wide
NAME     DESIRED     CURRENT    READY    AGE   CONTAINERS    IMAGES     SELECTOR

kubectl set image deployment deployment_name container_name
kubectl set image deployment hello-world-rest-api hello-world-rest-api=DUMMY_IMAGE:TEST

kubectl get rs -o wide
kubectl get pods
kubectl describe pod hello-world-rest-api-85995ddd5c-msjsm
kubectl get events --sort-by=.metadata.creationTimestamp

kubectl set image deployment deployment_name container_name=repository_name/image_name:tag
kubectl set image deployment hello-world-rest-api hello-world-rest-api=in28min/hello-world-rest-api:0.0.2.RELEASE

kubectl get events --sort-by=.metadata.creationTimestamp


A deployment is very, very important to make sure that you are able to update new releases of applications without downtime. The strategy which the deployment 
is using by default is something called rolling updates. What it does is, let's say I have five instances of V1, and I want to update to V2, the rolling update 
strategy, it updates one pod at a time. So it launches a new pod for V2. Once it's up and running, it reduces the number of pods for V1. Next, it increases the 
number of pods for V2, and so on and so forth until the number of pods for V1 becomes zero and all the traffic goes then to V2.

------------------------------------------------------------------------------------------------------
206. Step 10 - Quick Review of Kubernetes Concepts - Pods, Replica Sets & Deployments


A pod is nothing but a wrapper for a set of containers. A pod has an IP address and it has things like labels, annotations and stuff like that.

Now, why do we need a replica set? A replica set ensures that a specific number of pods are always running.
So if you say replica set three instances, then it ensures that three instances of the pods are always running.Even if you kill one of the instances of the pod, 
replica set would observe that and it would bring up a new instance of the pod.
In practice, you'd see that a replica set is always tied with a specific release version. So, you'll have a replica set, V1 and that would be maintaining a specified 
number of instances of the V1 release. So a replica set V1 is responsible for making sure that that specified number of instances of version one of the application 
are always running.

Why do we need a deployment?
A deployment ensures that a release upgrade, a switch from V one to V two happens without a hitch. You don't really want to have down times when you release new versions 
of applications and that's where deployment plays a key role. There are a variety of deployment strategies. When I'm releasing a new version of the application, I might want 
to actually send 50% of traffic to V one and 50% of traffic to V two. Or, I would want actually do something like a rolling update where I want to first create one instance of V two, 
test it, once it's fine, I would reduce the number of instances of V one. After that, I'll create a new instance of V two. Once it's up and running, I'll reduce the number of instances 
of V one. And so on and so forth until the number of instances of V one gets reduced to zero. The default deployment strategy is rolling updates.


------------------------------------------------------------------------------------------------------
207. Step 11 - Understanding Services in Kubernetes

kubectl get pods -o wide

kubectl delete pod pod_name
kubectl delete pod hello-world-rest-api-67c79fd44f-n6c7l

kubectl get pods -o wide
kubectl delete pod hello-world-rest-api-67c79fd44f-8bhdt



In the Kubernetes world, a pod is a throwaway unit. Your pods might go down, new pods might come up. Whenever I do a new release, there might be several new pods which are created, 
and the old pods completely go away, irrespective of all the changes happening with the pods. We don't want the consumer side of things to get affected. We don't want the user of 
the application to use a different URL. That's the role of a service. The role of a service is to provide an always available external interface to the applications which are running 
inside the pods. A service basically allows your application to receive traffic through a permanent lifetime IP address. Now, when was this service created?
This service was created when we did an exposed deployment. Earlier in the course, we executed kubectl expose deployment hello world rest API hyphen hyphen type is equal to load balancer 
hyphen hyphen port is equal to 80 80. This is when the service was created with an IP address and that's the IP address that we are using to access the application.

A load balancer can load balance between multiple pods. 
cluster IP service mean? A cluster IP service can only be accessed from inside the cluster. You won't be able to access this service from outside the cluster. cluster IP service doesn't 
have external IP for any specific service. So, if you have any services which are directly consumed inside your cluster, you can have them use a cluster IP.


------------------------------------------------------------------------------------------------------
209. Step 13 - Understanding Kubernetes Architecture - Master Node and Nodes


What are the important components that are running as part of your Master Node?
The most important component that is running as part of your Master Node is something called ETCD. That's the distributed database, E-T-C-D. All the configuration 
changes that we are making, all the deployments that we are creating, all the scaling operations that we are performing, all the details of those are stored in a 
Distributed Database. What we are doing when we are executing those commands is setting the desired state for Kubernetes. We are telling Kubernetes I would want five 
instances of application A, I would want 10 instances of application B. That's what is called desired state and the desired state is stored in the Distributed Database, 
E-T-C-D. So, all the Kubernetes resources like deployment, services, all the configuration that we make is stored finally into this Distributed Database. The great thing
about this database is that it is distributed. Typically, we would recommend you to have about three to five replicas of this database so that the Kubernetes cluster 
state is not lost. 

The second important component inside the Master Node is something called the API Server (kube-apiserver). Earlier we were executing commands from Kubectl. We were making
changes from the Google Cloud console from the interface provided by Google Cloud. How does kubectl talk to Kubernetes cluster? How does the Google Cloud interface or the
Google Cloud console talk to the Kubernetes cluster? The way they make their changes is through the API server. If I try to make a change through kubectl or if I try to 
make a change to the Google Cloud console, the change is submitted to this API server and processed from here. 

The other two important components which are present in here are the Scheduler and the Controller Manager. 
The scheduler is responsible for scheduling the pods onto the Nodes. In a Kubernetes cluster, you'll have several Nodes and when we are creating a new pod, you need to 
decide which Node the pod has to be scheduled on to. The decision might be based on how much memories available and how much CPU is available. Are there any pod conflicts
and a lot of such factors? So, Scheduler considers all those factors and schedules the pods onto the appropriate Nodes. 

The Controller Manager manages the overall health of the cluster. Wherever we are executing kubectl commands, we are updating the desired state. The kubectl manager makes
sure that whatever desired state that we have, we would want 10 instances of application A, we would want 10 instances of application B, we would want five instances of 
release 2. All those changes needs to be executed into the cluster and the Controller Manager is responsible for that. It makes sure that the actual state of the Kubernetes
cluster matches the desired state. 
The important thing about a Master Node, is typically the user applications like our Hello World rests API will not be scheduled onto the Master Node. All the user applications 
would be running typically in PODS inside the Worker Nodes or just the Node. So, one of the important components of the Node is the applications that we would want to run 
the hello World REST API of web application or things like that. Where would they all be running? They'll be running inside PODS on a single Node you might have several 
PODS running. 
Now what are the other components which are present on the Node? The other components which are present on the Node are number one, is a Node Agent. It's called a Kubelet. 
K-U-B-E-L-E-T. What is the job of a kubelet? The job of a kubelet is to make sure that it monitors what's happening on the Node and communicates it back to the Master Node. 
So, if a pod goes down, what does the Node Agent do? It reports it to the Controller Manager. 
The other component which is present in here is a Networking Component called the kube-proxy.
Earlier we created a deployment and we exposed the deployment as a service. How is that possible? That is possible through the Networking Component. It helps you in exposing 
services around your Nodes and your PODS. 
The other important component of the Worker Node is the Container Runtime. You want to run containers inside our PODS and these need the Container Runtime. The most frequently 
used Container Runtime is Docker. Actually, you can use Kubernetes with any O-C-I Open Container Interface, Runtime spec implementations. So, we talked a lot about what 
is present on the Master Node and what is present on the Node or the Worker Nodes. Before we end this specific section
let's discuss a few important questions. 
The first question we already talked about does a Master Node run any of the application related containers? Does it run Hello 
world REST API and things like that? The answer to this is, no. The Master Node is typically having only this stuff which is related to what is needed to control your 
Worker Nodes or the Nodes. 
Now, the second question is, can you only run docker containers in Kubernetes? The answer to that is, no. We already talked about this as well, right? If your container 
is compatible with O-C-I Open Container Interface, that's fine. You can run those containers in Kubernetes.
Let's get to the third question which is a very interesting one. What happens if the Master Node goes down or what happens if a specific service on a Master Node goes 
down? Will the applications go down? The answer to that is, no. The applications can continue to run working even with the Master Node down. When I'm executing a URL 
to access an application the Master Node does not get involved at all. The only thing that would be involved in those kind of situations are just the Worker Nodes, the 
Nodes which are doing the work. So, even if the Master Node goes down or the API Server goes down our applications would continue to be working. You'll not be able to 
make changes to them but the existing applications would continue to run. 

kubectl get componentstatuses.
 
------------------------------------------------------------------------------------------------------
